{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "284601b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6261ff1",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2873c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.Input(shape=(150, 150, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    \n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67e47c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.8)\n",
    "\n",
    "loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e349724",
   "metadata": {},
   "source": [
    "## 1) Loss function for binary classification is binary crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd16a56",
   "metadata": {},
   "source": [
    "## 2) Total number of parameters: 11,215,873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52615a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d5b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceaac3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode= 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aabb4ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = val_gen.flow_from_directory(\n",
    "    './test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode= 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c999ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 06:28:25.180085: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-16 06:28:25.934562: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-16 06:28:25.935133: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-16 06:28:25.935171: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-11-16 06:28:25.935811: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-16 06:28:25.935908: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 11s 109ms/step - loss: 0.6612 - accuracy: 0.6625 - val_loss: 0.5375 - val_accuracy: 0.8071\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 9s 108ms/step - loss: 0.5185 - accuracy: 0.7829 - val_loss: 0.5423 - val_accuracy: 0.7183\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.6207 - accuracy: 0.6612 - val_loss: 0.5483 - val_accuracy: 0.7487\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.4907 - accuracy: 0.7660 - val_loss: 0.4690 - val_accuracy: 0.8096\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.3494 - accuracy: 0.8570 - val_loss: 0.3675 - val_accuracy: 0.8299\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.2452 - accuracy: 0.9141 - val_loss: 0.3757 - val_accuracy: 0.8477\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 9s 106ms/step - loss: 0.1117 - accuracy: 0.9655 - val_loss: 0.3980 - val_accuracy: 0.8426\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 0.4692 - val_accuracy: 0.8198\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.6084 - val_accuracy: 0.8299\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 9s 107ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.6296 - val_accuracy: 0.8096\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d826f5a1",
   "metadata": {},
   "source": [
    "## 3) Median of training accuracy: 0.9 (closest one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c912a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855081796646118"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84c5d4",
   "metadata": {},
   "source": [
    "## 4) Standard deviation of training loss: 0,33 (closest one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6290f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24127188162425375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76868bd",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92eaaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85fd2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen_augmentation = ImageDataGenerator(rescale=1./255,\n",
    "                               preprocessing_function=preprocess_input,\n",
    "                                rotation_range=40,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f8c5652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_gen_augmentation.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode= 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b57134c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 15s 193ms/step - loss: 0.8093 - accuracy: 0.5050 - val_loss: 1.0202 - val_accuracy: 0.5381\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 15s 192ms/step - loss: 0.7033 - accuracy: 0.5000 - val_loss: 0.6654 - val_accuracy: 0.5558\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 15s 191ms/step - loss: 0.6980 - accuracy: 0.5251 - val_loss: 0.6555 - val_accuracy: 0.6193\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 16s 194ms/step - loss: 0.6956 - accuracy: 0.5075 - val_loss: 0.6514 - val_accuracy: 0.6853\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 15s 190ms/step - loss: 0.6966 - accuracy: 0.5188 - val_loss: 0.6513 - val_accuracy: 0.6954\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 15s 193ms/step - loss: 0.6945 - accuracy: 0.5263 - val_loss: 0.6521 - val_accuracy: 0.6954\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 15s 193ms/step - loss: 0.6940 - accuracy: 0.5188 - val_loss: 0.6521 - val_accuracy: 0.6904\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 15s 193ms/step - loss: 0.6936 - accuracy: 0.5100 - val_loss: 0.6521 - val_accuracy: 0.6904\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 15s 192ms/step - loss: 0.6934 - accuracy: 0.5188 - val_loss: 0.6519 - val_accuracy: 0.6980\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 15s 192ms/step - loss: 0.6932 - accuracy: 0.5113 - val_loss: 0.6493 - val_accuracy: 0.6853\n"
     ]
    }
   ],
   "source": [
    "history_1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51715464",
   "metadata": {},
   "source": [
    "## 5) Mean validation loss (epochs of augmentation): 0,66 (closest one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bff5f54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6901232481002808"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history_1.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dd735",
   "metadata": {},
   "source": [
    "## 5) Average validation accuracy of last 5 epochs: 0,84 (closest one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f43d3b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6918781638145447"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history_1.history['val_accuracy'][5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
